{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T05:14:55.337325899Z",
     "start_time": "2023-10-30T05:14:54.155665993Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import enum\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from spear.labeling import PreLabels\n",
    "import numpy as np\n",
    "from spear.cage import Cage\n",
    "from utils import custom_dataset, train_all_LF\n",
    "from generate_LF import get_variables\n",
    "from spear.labeling import labeling_function, ABSTAIN, preprocessor, continuous_scorer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T05:14:55.471354362Z",
     "start_time": "2023-10-30T05:14:55.338338708Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "from resnet18 import ResNet, BasicBlock\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from resnet18 import ResNet, BasicBlock\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaring ClassLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T05:14:55.474010184Z",
     "start_time": "2023-10-30T05:14:55.470961873Z"
    }
   },
   "outputs": [],
   "source": [
    "ABSTAIN = None\n",
    "\n",
    "class ClassLabels(enum.Enum):\n",
    "    LYMPHOCYTE= 0\n",
    "    NONLYMPHOCYTE = 1\n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Labelling Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LFs for Class 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from spear.labeling import labeling_function, ABSTAIN, preprocessor, continuous_scorer\n",
    "import re\n",
    "path = \"../data/models/100/\"\n",
    "# SVM\n",
    "@continuous_scorer()\n",
    "def svm_V1(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten() # x is 28x28x3 input img \n",
    "    svm = pickle.load(open(path+'0_svm.pkl','rb'))\n",
    "    confidence_scores = svm.predict_proba([x])\n",
    "    # print(confidence_scores)\n",
    "    return float(confidence_scores[0][0]) #only called when model doesn't ABSTAIN, output confidence on class label\n",
    "\n",
    "@labeling_function(cont_scorer=svm_V1, label=ClassLabels.LYMPHOCYTE)\n",
    "def LF_svm0_V1(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    svm = pickle.load(open(path+'0_svm.pkl','rb'))\n",
    "    \n",
    "    if svm.predict_proba([x])[0][0]>0.80: \n",
    "        return ClassLabels.LYMPHOCYTE # Return label only if confidence > 0.8\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "    \n",
    "# KNN\n",
    "@continuous_scorer()\n",
    "def knn_V1(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten() # x is 28x28x3 input img \n",
    "    knn = pickle.load(open(path+'0_knn.pkl','rb'))\n",
    "    confidence_scores =knn.predict_proba([x])\n",
    "    # print(confidence_scores)\n",
    "    return float(confidence_scores[0][0]) #only called when model doesn't ABSTAIN, output confidence on class label\n",
    "\n",
    "@labeling_function(cont_scorer=knn_V1, label=ClassLabels.LYMPHOCYTE)\n",
    "def LF_knn0_V1(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    knn= pickle.load(open(path+'0_knn.pkl','rb'))\n",
    "    \n",
    "    if knn.predict_proba([x])[0][0]>0.80: \n",
    "        return ClassLabels.LYMPHOCYTE # Return label only if confidence > 0.8\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "\n",
    "# DTC\n",
    "@continuous_scorer()\n",
    "def dtc_V1(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten() # x is 28x28x3 input img \n",
    "    dtc = pickle.load(open(path+'0_dtc.pkl','rb'))\n",
    "    confidence_scores = dtc.predict_proba([x])\n",
    "    # print(confidence_scores)\n",
    "    return float(confidence_scores[0][0]) #only called when model doesn't ABSTAIN, output confidence on class label\n",
    "\n",
    "@labeling_function(cont_scorer=dtc_V1, label=ClassLabels.LYMPHOCYTE)\n",
    "def LF_dtc0_V1(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    dtc = pickle.load(open(path+'0_dtc.pkl','rb'))\n",
    "    \n",
    "    if dtc.predict_proba([x])[0][0]>0.80: \n",
    "        return ClassLabels.LYMPHOCYTE # Return label only if confidence > 0.8\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "    \n",
    "# RF\n",
    "@continuous_scorer()\n",
    "def rf_V1(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten() # x is 28x28x3 input img \n",
    "    rf = pickle.load(open(path+'0_rf.pkl','rb'))\n",
    "    confidence_scores = rf.predict_proba([x])\n",
    "    # print(confidence_scores)\n",
    "    return float(confidence_scores[0][0]) #only called when model doesn't ABSTAIN, output confidence on class label\n",
    "\n",
    "@labeling_function(cont_scorer=rf_V1, label=ClassLabels.LYMPHOCYTE)\n",
    "def LF_rf0_V1(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    rf = pickle.load(open(path+'0_rf.pkl','rb'))\n",
    "    \n",
    "    if rf.predict_proba([x])[0][0]>0.80: \n",
    "        return ClassLabels.LYMPHOCYTE # Return label only if confidence > 0.8\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "    \n",
    "    \n",
    "# LR\n",
    "@continuous_scorer()\n",
    "def lr_V1(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten() # x is 28x28x3 input img \n",
    "    lr = pickle.load(open(path+'0_lr.pkl','rb'))\n",
    "    confidence_scores = lr.predict_proba([x])\n",
    "    # print(confidence_scores)\n",
    "    return float(confidence_scores[0][0]) #only called when model doesn't ABSTAIN, output confidence on class label\n",
    "\n",
    "@labeling_function(cont_scorer=lr_V1, label=ClassLabels.LYMPHOCYTE)\n",
    "def LF_lr0_V1(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    lr = pickle.load(open(path+'0_lr.pkl','rb'))\n",
    "    \n",
    "    if lr.predict_proba([x])[0][0]>0.80: \n",
    "        return ClassLabels.LYMPHOCYTE # Return label only if confidence > 0.8\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "    \n",
    "    \n",
    "# NB\n",
    "@continuous_scorer()\n",
    "def nb_V1(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten() # x is 28x28x3 input img \n",
    "    nb = pickle.load(open(path+'0_nb.pkl','rb'))\n",
    "    confidence_scores = nb.predict_proba([x])\n",
    "    # print(confidence_scores)\n",
    "    return float(confidence_scores[0][0]) #only called when model doesn't ABSTAIN, output confidence on class label\n",
    "\n",
    "@labeling_function(cont_scorer=nb_V1, label=ClassLabels.LYMPHOCYTE)\n",
    "def LF_nb0_V1(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    nb = pickle.load(open(path+'0_nb.pkl','rb'))\n",
    "    \n",
    "    if nb.predict_proba([x])[0][0]>0.80: \n",
    "        return ClassLabels.LYMPHOCYTE # Return label only if confidence > 0.8\n",
    "    else: \n",
    "        return ABSTAIN"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T05:14:55.482246225Z",
     "start_time": "2023-10-30T05:14:55.479431634Z"
    }
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LFs for Class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T05:14:55.489812248Z",
     "start_time": "2023-10-30T05:14:55.482331328Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# SVM\n",
    "@continuous_scorer()\n",
    "def svm_V1(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten() # x is 28x28x3 input img \n",
    "    svm = pickle.load(open(path+'1_svm.pkl','rb'))\n",
    "    confidence_scores = svm.predict_proba([x])\n",
    "    # print(confidence_scores)\n",
    "    return float(confidence_scores[0][1]) #only called when model doesn't ABSTAIN, output confidence on class label\n",
    "\n",
    "@labeling_function(cont_scorer=svm_V1, label=ClassLabels.NONLYMPHOCYTE)\n",
    "def LF_svm1_V1(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    svm = pickle.load(open(path+'0_svm.pkl','rb'))\n",
    "    \n",
    "    if svm.predict_proba([x])[0][1]>0.80: \n",
    "        return ClassLabels.NONLYMPHOCYTE # Return label only if confidence > 0.8\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "    \n",
    "# KNN\n",
    "@continuous_scorer()\n",
    "def knn_V1(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten() # x is 28x28x3 input img \n",
    "    knn = pickle.load(open(path+'1_knn.pkl','rb'))\n",
    "    confidence_scores =knn.predict_proba([x])\n",
    "    # print(confidence_scores)\n",
    "    return float(confidence_scores[0][1]) #only called when model doesn't ABSTAIN, output confidence on class label\n",
    "\n",
    "@labeling_function(cont_scorer=knn_V1, label=ClassLabels.NONLYMPHOCYTE)\n",
    "def LF_knn1_V1(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    knn= pickle.load(open(path+'1_knn.pkl','rb'))\n",
    "    \n",
    "    if knn.predict_proba([x])[0][1]>0.80: \n",
    "        return ClassLabels.NONLYMPHOCYTE # Return label only if confidence > 0.8\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "\n",
    "\n",
    "# DTC\n",
    "@continuous_scorer()\n",
    "def dtc_V1(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten() # x is 28x28x3 input img \n",
    "    dtc = pickle.load(open(path+'1_dtc.pkl','rb'))\n",
    "    confidence_scores = dtc.predict_proba([x])\n",
    "    # print(confidence_scores)\n",
    "    return float(confidence_scores[0][1]) #only called when model doesn't ABSTAIN, output confidence on class label\n",
    "\n",
    "@labeling_function(cont_scorer=dtc_V1, label=ClassLabels.NONLYMPHOCYTE)\n",
    "def LF_dtc1_V1(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    dtc = pickle.load(open(path+'1_dtc.pkl','rb'))\n",
    "    \n",
    "    if dtc.predict_proba([x])[0][1]>0.80: \n",
    "        return ClassLabels.NONLYMPHOCYTE # Return label only if confidence > 0.8\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "    \n",
    "# RF\n",
    "@continuous_scorer()\n",
    "def rf_V1(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten() # x is 28x28x3 input img \n",
    "    rf = pickle.load(open(path+'1_rf.pkl','rb'))\n",
    "    confidence_scores = rf.predict_proba([x])\n",
    "    # print(confidence_scores)\n",
    "    return float(confidence_scores[0][1]) #only called when model doesn't ABSTAIN, output confidence on class label\n",
    "\n",
    "@labeling_function(cont_scorer=rf_V1, label=ClassLabels.NONLYMPHOCYTE)\n",
    "def LF_rf1_V1(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    rf = pickle.load(open(path+'1_rf.pkl','rb'))\n",
    "    \n",
    "    if rf.predict_proba([x])[0][1]>0.80: \n",
    "        return ClassLabels.NONLYMPHOCYTE # Return label only if confidence > 0.8\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "    \n",
    "    \n",
    "# LR\n",
    "@continuous_scorer()\n",
    "def lr_V1(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten() # x is 28x28x3 input img \n",
    "    lr = pickle.load(open(path+'1_lr.pkl','rb'))\n",
    "    confidence_scores = lr.predict_proba([x])\n",
    "    # print(confidence_scores)\n",
    "    return float(confidence_scores[0][1]) #only called when model doesn't ABSTAIN, output confidence on class label\n",
    "\n",
    "@labeling_function(cont_scorer=lr_V1, label=ClassLabels.NONLYMPHOCYTE)\n",
    "def LF_lr1_V1(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    lr = pickle.load(open(path+'1_lr.pkl','rb'))\n",
    "    \n",
    "    if lr.predict_proba([x])[0][1]>0.80: \n",
    "        return ClassLabels.NONLYMPHOCYTE # Return label only if confidence > 0.8\n",
    "    else: \n",
    "        return ABSTAIN\n",
    "    \n",
    "    \n",
    "# NB\n",
    "@continuous_scorer()\n",
    "def nb_V1(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten() # x is 28x28x3 input img \n",
    "    nb = pickle.load(open(path+'1_nb.pkl','rb'))\n",
    "    confidence_scores = nb.predict_proba([x])\n",
    "    # print(confidence_scores)\n",
    "    return float(confidence_scores[0][1]) #only called when model doesn't ABSTAIN, output confidence on class label\n",
    "\n",
    "@labeling_function(cont_scorer=nb_V1, label=ClassLabels.NONLYMPHOCYTE)\n",
    "def LF_nb1_V1(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()  \n",
    "    nb = pickle.load(open(path+'1_nb.pkl','rb'))\n",
    "    \n",
    "    if nb.predict_proba([x])[0][1]>0.80: \n",
    "        return ClassLabels.NONLYMPHOCYTE # Return label only if confidence > 0.8\n",
    "    else: \n",
    "        return ABSTAIN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating LFs & Labelling dataset "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LFSet\n",
    "Placeholder for declared LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T05:14:55.492125582Z",
     "start_time": "2023-10-30T05:14:55.491014486Z"
    }
   },
   "outputs": [],
   "source": [
    "from spear.labeling import LFSet\n",
    "\n",
    "LFS = [\n",
    "    LF_rf0_V1,\n",
    "    LF_rf1_V1, \n",
    "    LF_knn0_V1,\n",
    "    LF_knn1_V1, \n",
    "    LF_lr0_V1,\n",
    "    LF_lr1_V1, \n",
    "    LF_dtc0_V1,\n",
    "    LF_dtc1_V1,\n",
    "    LF_nb0_V1,\n",
    "    LF_nb1_V1, \n",
    "    LF_svm0_V1,\n",
    "    LF_svm1_V1,  \n",
    "  \n",
    "]\n",
    "\n",
    "QT2 = 0.9\n",
    "QC2 = 0.8\n",
    "\n",
    "qt1 = np.array([0.9999,0.9999,0.9999,0.9999,0.9999,0.9999,0.9999,0.9999,0.9999])\n",
    "qc1 = np.array([0.99999,0.99999,0.9999,0.9999,0.9999,0.9999,0.9999,0.9999,0.9999])\n",
    "\n",
    "rules = LFSet(\"BM_LF\")\n",
    "rules.add_lf_list(LFS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T05:14:56.746662274Z",
     "start_time": "2023-10-30T05:14:55.493747492Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-30 10:44:55.616134: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-30 10:44:55.640127: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-30 10:44:56.054584: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from utils import custom_dataset, train_all_LF\n",
    "from generate_LF import get_variables\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "\n",
    "classes, label_frac, data_path,save_path = get_variables()\n",
    "dataset,x,y = custom_dataset(classes=classes,path=data_path ,fraction=label_frac)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "(126, 224, 224, 3)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T05:14:56.751534207Z",
     "start_time": "2023-10-30T05:14:56.748665920Z"
    }
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T05:14:56.761003353Z",
     "start_time": "2023-10-30T05:14:56.751218835Z"
    }
   },
   "outputs": [],
   "source": [
    "def cage_loop(LFS, max_iters=10, threshold=10**-5, img_per_class = 150):\n",
    "    from tensorflow.python.keras.utils import np_utils\n",
    "    # Paths\n",
    "    log_path_cage = './cage_loop/log.txt' \n",
    "    params_path = None\n",
    "    path_json = \"./cage_loop/labels.json\"\n",
    "    U_path_pkl = \"./cage_loop/unlabelled.pkl\"\n",
    "    L_path_pkl = \"./cage_loop/labelled.pkl\"\n",
    "\n",
    "    # Loading Data\n",
    "    classes,label_frac,data_path,save_path = get_variables()\n",
    "    print(\"Classes used in expt:\",classes)\n",
    "    dataset,x,y = custom_dataset(classes=classes, path=data_path, fraction=label_frac)\n",
    "\n",
    "    xu = np.array(dataset['test_images'])\n",
    "    yu = np.array(dataset['test_labels'])\n",
    "    print(np.shape(xu),np.shape(yu))\n",
    "    # Creating rules\n",
    "    n_lfs = len(LFS)\n",
    "    rules = LFSet(\"BM_LF\")\n",
    "    rules.add_lf_list(LFS)\n",
    "    \n",
    "    confidence_list = []\n",
    "    val_scores = []\n",
    "\n",
    "    for i in range(max_iters):\n",
    "        # Train Models in LFs\n",
    "        train_all_LF(x,y,len(classes),save_path,label_frac)\n",
    "\n",
    "        # Unlabelled\n",
    "        u_noisy_labels = PreLabels(name=\"bmnist_rem_ul\",\n",
    "                                    data=xu,\n",
    "                                    rules=rules,\n",
    "                                    labels_enum=ClassLabels,\n",
    "                                    num_classes=len(classes))\n",
    "        # Lu,Su = u_noisy_labels.get_labels()\n",
    "        u_noisy_labels.generate_pickle(U_path_pkl)\n",
    "\n",
    "        # Labelled\n",
    "        l_noisy_labels = PreLabels(name=\"bmnist_l\",\n",
    "                                    data=x,\n",
    "                                    gold_labels=y,\n",
    "                                    rules=rules,\n",
    "                                    labels_enum=ClassLabels,\n",
    "                                    num_classes=len(classes))\n",
    "        # Ll,Sl = l_noisy_labels.get_labels()\n",
    "        l_noisy_labels.generate_pickle(L_path_pkl)\n",
    "        l_noisy_labels.generate_json(path_json)\n",
    "\n",
    "\n",
    "        # Cage\n",
    "        cage = Cage(path_json = path_json, n_lfs = n_lfs)\n",
    "        if params_path is not None: \n",
    "            cage.load_params(load_path = params_path)\n",
    "        else:\n",
    "            params_path = './cage_loop/params.pkl' \n",
    "        \n",
    "        probs = cage.fit_and_predict_proba(path_pkl = U_path_pkl, path_test = L_path_pkl, path_log = log_path_cage, qt = QT2, qc = QC2, metric_avg = ['macro'], n_epochs = 100, lr = 0.01)\n",
    "        labels = np.argmax(probs, 1)\n",
    "\n",
    "        print(labels)\n",
    "\n",
    "        values, frequency = np.unique(yu, return_counts=True)\n",
    "        for values, frequency in zip(values, frequency):\n",
    "            print(f\"Labels of Lake Class {values}: {frequency}\")\n",
    "\n",
    "        values, frequency = np.unique(y, return_counts=True)\n",
    "        for values, frequency in zip(values, frequency):\n",
    "            print(f\"Labels of Labelled Set {values}: {frequency}\")\n",
    "        \n",
    "        print(\"=\"*45)\n",
    "        print(\"Iteration\",i)\n",
    "        print(\"Shape of Labeled Data:\",x.shape)\n",
    "        print(\"Shape of Unlabeled Data:\",xu.shape)\n",
    "        print(\"Accuracy on unlabelled images:\",accuracy_score(labels,yu)*100)\n",
    "        print(\"=\"*45)\n",
    "        \n",
    "        cage.save_params(save_path = params_path)\n",
    "\n",
    "        confidence = np.array([np.max(i) for i in probs])\n",
    "        confidence_list.append(confidence)\n",
    "        print(i,probs.shape)\n",
    "\n",
    "        # Getting indices of probabilities in decreasing order\n",
    "        idx = np.argsort(confidence)\n",
    "        idx = idx[::-1] \n",
    "\n",
    "        # Number of images per class (5%)\n",
    "        # img_per_class = int(0.05*len(confidence)/len(classes))\n",
    "\n",
    "        # Number of images per class (50)\n",
    "        \n",
    "        \n",
    "        print(\"Num img per class =\",img_per_class)\n",
    "\n",
    "        pop_list = [] #list of indices of images to be added\n",
    "        label_count = []\n",
    "\n",
    "        for j in idx:\n",
    "            if confidence[j]>threshold and label_count.count(labels[j])<img_per_class:\n",
    "                pop_list.append(j)\n",
    "                label_count.append(labels[j])\n",
    "        \n",
    "        print(\"Number of images getting transferred:\", len(pop_list))\n",
    "        print('Accuracy of Pseudo-labelled img added to dataset:', accuracy_score(labels[pop_list],yu[pop_list])*100)\n",
    "        \n",
    "        x = np.append(x,xu[pop_list], axis=0)\n",
    "        y = np.append(y,labels[pop_list], axis=0)        \n",
    "        xu = np.delete(xu,pop_list, axis=0)\n",
    "        yu = np.delete(yu,pop_list, axis=0)\n",
    "\n",
    "        if len(pop_list)<5:\n",
    "            break\n",
    "\n",
    "        classes,label_frac,data_path,save_path = get_variables()\n",
    "\n",
    "\n",
    "    return x,y,xu, yu, confidence_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T05:41:18.752030314Z",
     "start_time": "2023-10-30T05:14:56.762346071Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes used in expt: [0, 1]\n",
      "(1100, 224, 224, 3) (1100,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atharvs/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained & Saved 6 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atharvs/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained & Saved 6 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1100/1100 [21:15<00:00,  1.16s/it]\n",
      "100%|██████████| 126/126 [02:34<00:00,  1.22s/it]\n",
      "100%|██████████| 100/100 [00:09<00:00, 11.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_test_accuracy_score: 0.5079365079365079\n",
      "test_average_metric: macro\tfinal_test_f1_score: 0.36363636363636365\n",
      "[1 0 0 ... 0 0 0]\n",
      "Labels of Lake Class 0: 558\n",
      "Labels of Lake Class 1: 542\n",
      "Labels of Labelled Set 0: 63\n",
      "Labels of Labelled Set 1: 63\n",
      "=============================================\n",
      "Iteration 0\n",
      "Shape of Labeled Data: (126, 224, 224, 3)\n",
      "Shape of Unlabeled Data: (1100, 224, 224, 3)\n",
      "Accuracy on unlabelled images: 50.90909090909091\n",
      "=============================================\n",
      "0 (1100, 2)\n",
      "Num img per class = 10\n",
      "Number of images getting transferred: 20\n",
      "Accuracy of Pseudo-labelled img added to dataset: 50.0\n"
     ]
    }
   ],
   "source": [
    "#  img_per_class: num images added per loop per class\n",
    "x, y, xu, yu, confidence_list = cage_loop(LFS, max_iters=1, threshold=10**-10,  img_per_class = 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9f5b4396ae54b339dce7091723dfd2c38ad833227f8e97d2a6323021886247d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
